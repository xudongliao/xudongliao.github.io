<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Xudong Liao </title> <meta name="author" content="Xudong Liao"> <meta name="description" content="Personal website of Xudong Liao"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8E%93&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://xudongliao.github.io/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?bf50d6d9dd867d3e0f3b0add94449649"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Xudong</span> Liao </h1> <p class="desc">PhD Candidate, HKUST, Hong Kong SAR, China</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/xudong-480.webp 480w,/assets/img/xudong-800.webp 800w,/assets/img/xudong-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/xudong.jpg?5cd1f30c3998a6d0c980476756090b7b" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="xudong.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>I am a Ph.D candidate in <a href="https://www.ust.hk/" rel="external nofollow noopener" target="_blank">Hong Kong University of Science and Technology (HKUST)</a>, advised by <a href="http://www.cse.ust.hk/~kaichen/" rel="external nofollow noopener" target="_blank">Prof. Kai Chen</a>. Before that, I received my B.Eng in Software Engineering in <a href="https://www.whu.edu.cn/" rel="external nofollow noopener" target="_blank">Wuhan University</a> (Outstanding Graduate) in 2020.</p> <p>In my research projects, I focus on:</p> <ul> <li>developing application-oriented optimizations for distributed systems, including <a href="https://xudongliao.github.io/assets/pdf/herald-nsdi24.pdf">Herald</a>. These systems are designed to enhance performance by leveraging unique application characteristics, such as utilizing embedding access patterns in DLRM training within Herald.</li> <li>building performant congestion control (CC) schemes using reinforcement learning techniques, including <a href="https://xudongliao.github.io/assets/pdf/astraea-eurosys24.pdf">Astraea</a>, <a href="https://xudongliao.github.io/assets/pdf/spine-conext22.pdf">Spine</a>, <a href="https://xudongliao.github.io/assets/pdf/mocc-eurosys22.pdf">MOCC</a> and <a href="https://xudongliao.github.io/assets/pdf/jury-eurosys25.pdf">Jury</a>. These initiatives are driven by my goal to make Deep Reinforcement Learning (DRL)-based CC schemes fair, efficient and also practical for real-world deployment.</li> </ul> <p>I was fortunate to be advised by <a href="https://person.zju.edu.cn/en/0020875" rel="external nofollow noopener" target="_blank">Prof. Yanjiao Chen</a> during my time at WHU. Additionally, I am fortunate to collaborate closely with <a href="https://grace-liu.github.io" rel="external nofollow noopener" target="_blank">Prof. Guyue Liu</a> from Peking University and <a href="https://zhizhenzhong.com/" rel="external nofollow noopener" target="_blank">Dr. Zhizhen Zhong</a> from MIT on several recent projects.</p> <h4 id="research-interests">Research Interests</h4> <ul> <li>Machine Learning System</li> <li>Optical Network</li> <li>Congestion Control</li> <li>Datacenter Networking</li> </ul> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jan 10, 2024</th> <td> Our paper Astraea accepted in EuroSys 2024! </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 07, 2023</th> <td> Co-first paper Herald accepted in NSDI 2024! </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 24, 2023</th> <td> Co-authored paper G3 accepted in SIGMOD 2023! </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 30, 2022</th> <td> Co-first paper Spine accepted in CoNEXT 2022! </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <p>* equal contribution</p> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">arXiv</abbr> </div> <div id="mfabric-arxiv" class="col-sm-8"> <div class="title">mFabric: An Efficient and Scalable Fabric for Mixture-of-Experts Training</div> <div class="author"> <em>Xudong Liao</em> ,  Yijun Sun ,  <a href="https://tianhan4.github.io" rel="external nofollow noopener" target="_blank">Han Tian</a> ,  <a href="https://xcwanandy.github.io" rel="external nofollow noopener" target="_blank">Xinchen Wan</a> ,  <a href="https://kl4805.github.io" rel="external nofollow noopener" target="_blank">Yilun Jin</a> ,  Zilong Wang ,  Zhenghang Ren ,  Xinyang Huang ,  Wenxue Li ,  Kin Fai Tse ,  <a href="https://zhizhenzhong.com/" rel="external nofollow noopener" target="_blank">Zhizhen Zhong</a> ,  Guyue Liu ,  Ying Zhang ,  Xiaofeng Ye ,  Yiming Zhang ,  and  <a href="http://www.cse.ust.hk/~kaichen/" rel="external nofollow noopener" target="_blank">Kai Chen</a> </div> <div class="periodical"> <em>arXiv:2501.03905</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/mfabric-arxiv.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Mixture-of-Expert (MoE) models outperform conventional models by selectively activating different subnets, named experts, on a per-token basis. This gated computation generates dynamic communications that cannot be determined beforehand, challenging the existing GPU interconnects that remain static during the distributed training process. In this paper, we advocate for a first-of-its-kind system, called mFabric, that unlocks topology reconfiguration during distributed MoE training. Towards this vision, we first perform a production measurement study and show that the MoE dynamic communication pattern has strong locality, alleviating the requirement of global reconfiguration. Based on this, we design and implement a regionally reconfigurable high-bandwidth domain on top of existing electrical interconnects using optical circuit switching (OCS), achieving scalability while maintaining rapid adaptability. We have built a fully functional mFabric prototype with commodity hardware and a customized collective communication runtime that trains state-of-the-art MoE models with in-training topology reconfiguration across 32 A100 GPUs. Large-scale packet-level simulations show that mFabric delivers comparable performance as the non-blocking fat-tree fabric while boosting the training cost efficiency (e.g., performance per dollar) of four representative MoE models by 1.2x–1.5x and 1.9x–2.3x at 100 Gbps and 400 Gbps link bandwidths, respectively.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">INFOCOM</abbr> </div> <div id="wan2025leo" class="col-sm-8"> <div class="title">A Generic and Efficient Communication Framework for Message-level In-Network Computing</div> <div class="author"> <a href="https://xcwanandy.github.io" rel="external nofollow noopener" target="_blank">Xinchen Wan</a> ,  Luyang Li ,  <a href="https://tianhan4.github.io" rel="external nofollow noopener" target="_blank">Han Tian</a> ,  <em>Xudong Liao</em> ,  Xinyang Huang ,  <a href="https://hydrazeng.github.io" rel="external nofollow noopener" target="_blank">Chaoliang Zeng</a> ,  Zilong Wang ,  Xinyu Yang ,  Ke Cheng ,  Qingsong Ning ,  Guyue Liu ,  Layong Luo ,  and  <a href="http://www.cse.ust.hk/~kaichen/" rel="external nofollow noopener" target="_blank">Kai Chen</a> </div> <div class="periodical"> <em>In Proceedings of the IEEE International Conference on Computer Communications (<b>INFOCOM 2025</b>)</em> , 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="/assets/pdf/leo-infocom25.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">EuroSys</abbr> </div> <div id="jury-eurosys" class="col-sm-8"> <div class="title">Achieving Fairness Generalizability for Learning-based Congestion Control with Jury</div> <div class="author"> <a href="https://tianhan4.github.io" rel="external nofollow noopener" target="_blank">Han Tian</a> ,  <em>Xudong Liao</em> ,  Decang Sun ,  <a href="https://hydrazeng.github.io" rel="external nofollow noopener" target="_blank">Chaoliang Zeng</a> ,  <a href="https://kl4805.github.io" rel="external nofollow noopener" target="_blank">Yilun Jin</a> ,  <a href="https://snowzjx.me" rel="external nofollow noopener" target="_blank">Junxue Zhang</a> ,  <a href="https://xcwanandy.github.io" rel="external nofollow noopener" target="_blank">Xinchen Wan</a> ,  Zilong Wang ,  Yong Wang ,  and  <a href="http://www.cse.ust.hk/~kaichen/" rel="external nofollow noopener" target="_blank">Kai Chen</a> </div> <div class="periodical"> <em>In Proceedings of the 20th ACM European Conference on Computer Systems (<b>EuroSys 2025</b>)</em> , 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="/assets/pdf/jury-eurosys25.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">EuroSys</abbr> </div> <div id="astraea-eurosys" class="col-sm-8"> <div class="title">Astraea: Towards Fair and Efficient Learning-based Congestion Control</div> <div class="author"> <em>Xudong Liao*</em> ,  <a href="https://tianhan4.github.io" rel="external nofollow noopener" target="_blank">Han Tian*</a> ,  <a href="https://hydrazeng.github.io" rel="external nofollow noopener" target="_blank">Chaoliang Zeng</a> ,  <a href="https://xcwanandy.github.io" rel="external nofollow noopener" target="_blank">Xinchen Wan</a> ,  and  <a href="http://www.cse.ust.hk/~kaichen/" rel="external nofollow noopener" target="_blank">Kai Chen</a> </div> <div class="periodical"> <em>In Proceedings of the 19th ACM European Conference on Computer Systems (<b>EuroSys 2024</b>)</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2403.01798" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="/assets/pdf/astraea-eurosys24.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/HKUST-SING/astraea" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Recent years have witnessed a plethora of learning-based solutions for congestion control (CC) that demonstrate better performance over traditional TCP schemes. However, they fail to provide consistently good convergence properties, including fairness, fast convergence and stability, due to the mismatch between their objective functions and these properties. Despite being intuitive, integrating these properties into existing learning-based CC is challenging, because: 1) their training environments are designed for the performance optimization of single flow but incapable of cooperative multi-flow optimization, and 2) there is no directly measurable metric to represent these properties into the training objective function. We present Astraea, a new learning-based congestion control that ensures fast convergence to fairness with stability. At the heart of Astraea is a multi-agent deep reinforcement learning framework that explicitly optimizes these convergence properties during the training process by enabling the learning of interactive policy between multiple competing flows, while maintaining high performance. We further build a faithful multi-flow environment that emulates the competing behaviors of concurrent flows, explicitly expressing convergence properties to enable their optimization during training. We have fully implemented Astraea and our comprehensive experiments show that Astraea can quickly converge to fairness point and exhibit better stability than its counterparts. For example, Astraea achieves near-optimal bandwidth sharing (i.e., fairness) when multiple flows compete for the same bottleneck, delivers up to 8.4x faster convergence speed and 2.8x smaller throughput deviation, while achieving comparable or even better performance over prior solutions.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NSDI</abbr> </div> <div id="herald-nsdi" class="col-sm-8"> <div class="title">Accelerating Neural Recommendation Training with Embedding Scheduling</div> <div class="author"> <a href="https://hydrazeng.github.io" rel="external nofollow noopener" target="_blank">Chaoliang Zeng*</a> ,  <em>Xudong Liao*</em> ,  Xiaodian Cheng ,  <a href="https://tianhan4.github.io" rel="external nofollow noopener" target="_blank">Han Tian</a> ,  <a href="https://xcwanandy.github.io" rel="external nofollow noopener" target="_blank">Xinchen Wan</a> ,  <a href="https://whwh1996.github.io" rel="external nofollow noopener" target="_blank">Hao Wang</a> ,  and  <a href="http://www.cse.ust.hk/~kaichen/" rel="external nofollow noopener" target="_blank">Kai Chen</a> </div> <div class="periodical"> <em>In Proceedings of the 21st USENIX Symposium on Networked Systems Design and Implementation (<b>NSDI 2024</b>)</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/herald-nsdi24.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/HKUST-SING/herald" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Deep learning recommendation models (DLRM) are extensively adopted to support many online services. Typical DLRM training frameworks adopt the parameter server (PS) in CPU servers to maintain memory-intensive embedding tables, and leverage GPU workers with embedding cache to accelerate compute-intensive neural network computation and enable fast embedding lookups. However, such distributed systems suffer from significant communication overhead caused by the embedding transmissions between workers and PS. Prior work reduces the number of cache embedding transmissions by compromising model accuracy, including oversampling hot embeddings or applying staleness-tolerant updates. This paper reveals that many of such transmissions can be avoided given the predictability and infrequency natures of in-cache embedding accesses in distributed training. Based on this observation, we explore a new direction to accelerate distributed DLRM training without compromising model accuracy, i.e., embedding scheduling—with the core idea of proactively determining "where embeddings should be trained" and "which embeddings should be synchronized" to increase the cache hit rate and decrease unnecessary updates, thus achieving a low communication overhead. To realize this idea, we design Herald, a real-time embedding scheduler consisting of two main components: an adaptive location-aware inputs allocator to determine where embeddings should be trained and an optimal communication plan generator to determine which embeddings should be synchronized. Our experiments with real-world workloads show that Herald reduces 48%-89% embedding transmissions, leading up to 2.11x and up to 1.61x better performance with TCP and RDMA, respectively, over 100 Gbps Ethernet for end-to-end DLRM training.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">SIGMOD</abbr> </div> <div id="wan2023g3" class="col-sm-8"> <div class="title">Scalable and Efficient Full-Graph GNN Training for Large Graphs</div> <div class="author"> <a href="https://xcwanandy.github.io" rel="external nofollow noopener" target="_blank">Xinchen Wan</a> ,  Kaiqiang Xu ,  <em>Xudong Liao</em> ,  <a href="https://kl4805.github.io" rel="external nofollow noopener" target="_blank">Yilun Jin</a> ,  <a href="http://www.cse.ust.hk/~kaichen/" rel="external nofollow noopener" target="_blank">Kai Chen</a> ,  and  <a href="https://xinjin.github.io" rel="external nofollow noopener" target="_blank">Xin Jin</a> </div> <div class="periodical"> <em>In Proceedings of the ACM on Management of Data (<b>SIGMOD 2023</b>)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/g3-sigmod23.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Graph Neural Networks (GNNs) have emerged as powerful tools to capture structural information from graph-structured data, achieving state-of-the-art performance on applications such as recommendation, knowledge graph, and search. Graphs in these domains typically contain hundreds of millions of nodes and billions of edges. However, previous GNN systems demonstrate poor scalability because large and interleaved computation dependencies in GNN training cause significant overhead in current parallelization methods. We present G3, a distributed system that can efficiently train GNNs over billion-edge graphs at scale. G3 introduces GNN hybrid parallelism which synthesizes three dimensions of parallelism to scale out GNN training by sharing intermediate results peer-to-peer in fine granularity, eliminating layer-wise barriers for global collective communication or neighbor replications as seen in prior works. G3 leverages locality-aware iterative partitioning and multi-level pipeline scheduling to exploit acceleration opportunities by distributing balanced workload among workers and overlapping computation with communication in both inter-layer and intra-layer training processes. We show via a prototype implementation and comprehensive experiments that G3 can achieve as much as 2.24x speedup in a 16-node cluster, and better final accuracy over prior works.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">CoNEXT</abbr> </div> <div id="spine-conext" class="col-sm-8"> <div class="title">Spine: An Efficient DRL-Based Congestion Control with Ultra-Low Overhead</div> <div class="author"> <a href="https://tianhan4.github.io" rel="external nofollow noopener" target="_blank">Han Tian*</a> ,  <em>Xudong Liao*</em> ,  <a href="https://hydrazeng.github.io" rel="external nofollow noopener" target="_blank">Chaoliang Zeng</a> ,  <a href="https://snowzjx.me" rel="external nofollow noopener" target="_blank">Junxue Zhang</a> ,  and  <a href="http://www.cse.ust.hk/~kaichen/" rel="external nofollow noopener" target="_blank">Kai Chen</a> </div> <div class="periodical"> <em>In Proceedings of the 18th International Conference on Emerging Networking EXperiments and Technologies (<b>CoNEXT 2022</b>)</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/spine-conext22.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Previous congestion control (CC) algorithms based on deep reinforcement learning (DRL) directly adjust flow sending rate to respond to dynamic bandwidth change, resulting in high inference overhead. Such overhead may consume considerable CPU resources and hurt the datapath performance. In this paper, we present Spine, a hierarchical congestion control algorithm that fully utilizes the performance gain from deep reinforcement learning but with ultra-low overhead. At its heart, Spine decouples the congestion control task into two subtasks in different timescales and handles them with different components: i) a lightweight CC executor that performs fine-grained control responding to dynamic bandwidth changes, and ii) an RL agent that works at a coarse-grained level that generates control sub-policies for the CC executor. Such two-level control architecture can provide fine-grained DRL-based control with a low model inference overhead. Real-world experiments and emulations show that Spine achieves consistent high performance across various network conditions with an ultra-low control overhead reduced by at least 80% compared to its DRL-based counterparts, similar to classic CC schemes such as Cubic.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">EuroSys</abbr> </div> <div id="mocc-eurosys" class="col-sm-8"> <div class="title">Multi-Objective Congestion Control</div> <div class="author"> Yiqing Ma ,  <a href="https://tianhan4.github.io" rel="external nofollow noopener" target="_blank">Han Tian</a> ,  <em>Xudong Liao</em> ,  <a href="https://snowzjx.me" rel="external nofollow noopener" target="_blank">Junxue Zhang</a> ,  Weiyan Wang ,  <a href="http://www.cse.ust.hk/~kaichen/" rel="external nofollow noopener" target="_blank">Kai Chen</a> ,  and  <a href="https://xinjin.github.io" rel="external nofollow noopener" target="_blank">Xin Jin</a> </div> <div class="periodical"> <em>In Proceedings of the 17th European Conference on Computer Systems (<b>EuroSys 2022</b>)</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/mocc-eurosys22.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Decades of research on Internet congestion control (CC) have produced a plethora of algorithms that optimize for different performance objectives. Applications face the challenge of choosing the most suitable algorithm based on their needs, and it takes tremendous efforts and expertise to customize CC algorithms when new demands emerge. In this paper, we explore a basic question: can we design a single CC algorithm to satisfy different objectives? We propose MOCC, the first multi-objective congestion control algorithm that attempts to address this question. The core of MOCC is a novel multi-objective reinforcement learning framework for CC to automatically learn the correlations between different application requirements and the corresponding optimal control policies. Under this framework, MOCC further applies transfer learning to transfer the knowledge from past experience to new applications, quickly adapting itself to a new objective even if it is unforeseen. We provide both user-space and kernel-space implementation of MOCC. Real-world Internet experiments and extensive simulations show that MOCC supports well multi-objective, competing or outperforming the best existing CC algorithms on each individual objectives, and quickly adapting to new application objectives in 288 seconds (14.2x faster than prior work) without compromising old ones.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%78%75%64%6F%6E%67.%6C%69%61%6F.%63%73@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=GXo0S_4AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/xudongliao" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/xudong-liao-602091140" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> </div> <div class="contact-note">Contact: xudong [dot] liao [dot] cs [at] gmail.com </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Xudong Liao. Last updated: February 21, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?8664456308d8a0b76907c75d01dd1dbf" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>